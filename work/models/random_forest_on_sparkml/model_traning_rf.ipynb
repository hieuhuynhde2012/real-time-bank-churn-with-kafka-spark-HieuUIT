{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.functions import col\n",
    "# from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "# from pyspark.ml.classification import RandomForestClassifier\n",
    "# from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "# # Tạo SparkSession\n",
    "# spark = SparkSession.builder.appName(\"ChurnPrediction\").getOrCreate()\n",
    "\n",
    "# # Đọc dữ liệu\n",
    "# df = spark.read.csv(\"C:/Users/PC/Desktop/Do_an_Big_data/PythonCodes/work/data/Churn_Modelling_FE.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# # Loại bỏ các cột không cần thiết\n",
    "# df = df.drop(\"RowNumber\", \"CustomerId\", \"Surname\")\n",
    "\n",
    "# # Chuyển đổi cột đầu ra thành kiểu số nguyên\n",
    "# df = df.withColumn(\"Exited\", col(\"Exited\").cast(\"integer\"))\n",
    "\n",
    "# # Kết hợp các đặc trưng thành một vector\n",
    "# feature_cols = [col for col in df.columns if col != \"Exited\"]\n",
    "# assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "# df = assembler.transform(df)\n",
    "\n",
    "# # Chuẩn hóa dữ liệu\n",
    "# scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "# scaler_model = scaler.fit(df)\n",
    "# df = scaler_model.transform(df)\n",
    "\n",
    "# # Chia tập train/test\n",
    "# train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# # Huấn luyện mô hình Random Forest\n",
    "# rf = RandomForestClassifier(featuresCol=\"scaled_features\", labelCol=\"Exited\", numTrees=100)\n",
    "# rf_model = rf.fit(train_data)\n",
    "\n",
    "# # Lưu mô hình\n",
    "# rf_model.write().overwrite().save(\"C:/Users/PC/Desktop/Do_an_Big_data/PythonCodes/work/models/random_forest_on_sparkml\")\n",
    "\n",
    "# # Dự đoán trên tập test\n",
    "# predictions = rf_model.transform(test_data)\n",
    "\n",
    "# # Hiển thị kết quả\n",
    "# display_cols = [\"Exited\", \"rawPrediction\", \"probability\", \"prediction\"]\n",
    "# predictions.select(display_cols).show(10, False)\n",
    "\n",
    "# # Đánh giá mô hình\n",
    "# accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"Exited\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "# precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"Exited\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "# recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"Exited\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "# f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"Exited\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "# binary_auc_evaluator = BinaryClassificationEvaluator(labelCol=\"Exited\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "\n",
    "# # Tính toán các chỉ số\n",
    "# accuracy = accuracy_evaluator.evaluate(predictions)\n",
    "# precision = precision_evaluator.evaluate(predictions)\n",
    "# recall = recall_evaluator.evaluate(predictions)\n",
    "# f1_score = f1_evaluator.evaluate(predictions)\n",
    "# auc_roc = binary_auc_evaluator.evaluate(predictions)\n",
    "\n",
    "# # In kết quả\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")\n",
    "# print(f\"Precision: {precision:.4f}\")\n",
    "# print(f\"Recall: {recall:.4f}\")\n",
    "# print(f\"F1 Score: {f1_score:.4f}\")\n",
    "# print(f\"AUC-ROC: {auc_roc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class distribution:\n",
      "+------+-----+\n",
      "|Exited|count|\n",
      "+------+-----+\n",
      "|     1| 1891|\n",
      "|     0| 7677|\n",
      "+------+-----+\n",
      "\n",
      "Balanced Class distribution:\n",
      "+------+-----+\n",
      "|Exited|count|\n",
      "+------+-----+\n",
      "|     0| 3912|\n",
      "|     1| 3757|\n",
      "+------+-----+\n",
      "\n",
      "Feature columns used in training: ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'BalanceSalary', 'TenureAge', 'ScoreAge', 'tenure_age', 'tenure_salary', 'score_age', 'score_salary', 'newAge', 'newCreditScore', 'AgeScore', 'BalanceScore', 'SalaryScore', 'newEstimatedSalary', 'score_balance', 'age_balance', 'balance_salary', 'age_hascrcard', 'product_utilization_rate_by_year', 'product_utilization_rate_by_salary', 'countries_monthly_average_salaries', 'Germany', 'Spain', 'Female', 'Male']\n",
      "Test data saved to C:/Users/PC/Desktop/Do_an_Big_data/PythonCodes/work/data/test_data.csv\n",
      "+------+--------------------------------------+----------------------------------------+----------+\n",
      "|Exited|rawPrediction                         |probability                             |prediction|\n",
      "+------+--------------------------------------+----------------------------------------+----------+\n",
      "|0     |[14.030188809848394,85.9698111901516] |[0.14030188809848393,0.859698111901516] |1.0       |\n",
      "|0     |[52.068175784113585,47.93182421588644]|[0.5206817578411357,0.4793182421588642] |0.0       |\n",
      "|0     |[80.70845669620752,19.291543303792476]|[0.8070845669620752,0.19291543303792477]|0.0       |\n",
      "|0     |[78.1445061827827,21.855493817217276] |[0.7814450618278271,0.21855493817217278]|0.0       |\n",
      "|0     |[80.56900689637973,19.43099310362027] |[0.8056900689637974,0.1943099310362027] |0.0       |\n",
      "|0     |[79.08772469900121,20.912275300998775]|[0.7908772469900123,0.20912275300998778]|0.0       |\n",
      "|0     |[60.59893088006609,39.40106911993391] |[0.6059893088006609,0.39401069119933907]|0.0       |\n",
      "|0     |[57.60611873767726,42.39388126232276] |[0.5760611873767725,0.4239388126232275] |0.0       |\n",
      "|0     |[36.878548079488176,63.12145192051181]|[0.3687854807948818,0.6312145192051182] |1.0       |\n",
      "|0     |[33.77820492840227,66.22179507159771] |[0.3377820492840228,0.6622179507159773] |1.0       |\n",
      "+------+--------------------------------------+----------------------------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Best Model Parameters: numTrees=100, maxDepth=10\n",
      "Accuracy: 0.8556\n",
      "Precision: 0.8556\n",
      "Recall: 0.8556\n",
      "F1 Score: 0.8556\n",
      "AUC-ROC: 0.9293\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Tạo SparkSession\n",
    "spark = SparkSession.builder.appName(\"ChurnPrediction\").getOrCreate()\n",
    "\n",
    "# Đọc dữ liệu\n",
    "df = spark.read.csv(\"C:/Users/PC/Desktop/Do_an_Big_data/PythonCodes/work/data/Churn_Modelling_FE.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Loại bỏ các cột không cần thiết\n",
    "df = df.drop(\"RowNumber\", \"CustomerId\", \"Surname\")\n",
    "\n",
    "# Chuyển đổi cột đầu ra thành kiểu số nguyên\n",
    "df = df.withColumn(\"Exited\", col(\"Exited\").cast(\"integer\"))\n",
    "\n",
    "# Kiểm tra phân phối lớp\n",
    "print(\"Original Class distribution:\")\n",
    "df.groupBy(\"Exited\").count().show()\n",
    "\n",
    "# Tách dữ liệu thành hai lớp\n",
    "df_majority = df.filter(col(\"Exited\") == 0)  # Lớp đa số\n",
    "df_minority = df.filter(col(\"Exited\") == 1)  # Lớp thiểu số\n",
    "\n",
    "# Oversampling lớp thiểu số\n",
    "fraction_minority = 2.0  # Nhân đôi số lượng mẫu lớp 1\n",
    "df_minority_oversampled = df_minority.sample(withReplacement=True, fraction=fraction_minority, seed=42)\n",
    "\n",
    "# Undersampling lớp đa số\n",
    "fraction_majority = 0.5  # Giảm một nửa số lượng mẫu lớp 0\n",
    "df_majority_undersampled = df_majority.sample(withReplacement=False, fraction=fraction_majority, seed=42)\n",
    "\n",
    "# Kết hợp lại dữ liệu\n",
    "df_balanced = df_majority_undersampled.union(df_minority_oversampled)\n",
    "\n",
    "# Kiểm tra phân phối lớp sau khi cân bằng\n",
    "print(\"Balanced Class distribution:\")\n",
    "df_balanced.groupBy(\"Exited\").count().show()\n",
    "\n",
    "# Kết hợp các đặc trưng thành một vector\n",
    "feature_cols = [col for col in df_balanced.columns if col != \"Exited\"]\n",
    "print(\"Feature columns used in training:\", feature_cols)\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "df_balanced = assembler.transform(df_balanced)\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
    "scaler_model = scaler.fit(df_balanced)\n",
    "df_balanced = scaler_model.transform(df_balanced)\n",
    "\n",
    "# Chia tập train/test\n",
    "train_data, test_data = df_balanced.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Lưu tập test vào file CSV (loại bỏ cột features và scaled_features)\n",
    "test_output_path = \"C:/Users/PC/Desktop/Do_an_Big_data/PythonCodes/work/data/test_data.csv\"\n",
    "test_data_for_csv = test_data.drop(\"features\", \"scaled_features\")\n",
    "test_data_for_csv.coalesce(1).write.mode(\"overwrite\").csv(test_output_path, header=True)\n",
    "print(f\"Test data saved to {test_output_path}\")\n",
    "\n",
    "# Huấn luyện mô hình Random Forest\n",
    "rf = RandomForestClassifier(featuresCol=\"scaled_features\", labelCol=\"Exited\", seed=42)\n",
    "\n",
    "# Tạo lưới tham số để tối ưu hóa\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [50, 100]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "# Sử dụng CrossValidator để chọn mô hình tốt nhất\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"Exited\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "cv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=3, seed=42)\n",
    "cv_model = cv.fit(train_data)\n",
    "\n",
    "# Lấy mô hình tốt nhất\n",
    "rf_model = cv_model.bestModel\n",
    "\n",
    "# Lưu mô hình\n",
    "rf_model.write().overwrite().save(\"C:/Users/PC/Desktop/Do_an_Big_data/PythonCodes/work/models/random_forest_on_sparkml\")\n",
    "\n",
    "# Dự đoán trên tập test\n",
    "predictions = rf_model.transform(test_data)\n",
    "\n",
    "# Hiển thị kết quả\n",
    "display_cols = [\"Exited\", \"rawPrediction\", \"probability\", \"prediction\"]\n",
    "predictions.select(display_cols).show(10, False)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"Exited\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"Exited\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"Exited\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"Exited\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "binary_auc_evaluator = BinaryClassificationEvaluator(labelCol=\"Exited\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "\n",
    "# Tính toán các chỉ số\n",
    "accuracy = accuracy_evaluator.evaluate(predictions)\n",
    "precision = precision_evaluator.evaluate(predictions)\n",
    "recall = recall_evaluator.evaluate(predictions)\n",
    "f1_score = f1_evaluator.evaluate(predictions)\n",
    "auc_roc = binary_auc_evaluator.evaluate(predictions)\n",
    "\n",
    "# In kết quả\n",
    "print(f\"Best Model Parameters: numTrees={rf_model.getNumTrees}, maxDepth={rf_model.getMaxDepth()}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "\n",
    "# Dừng SparkSession\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Exited|count|\n",
      "+------+-----+\n",
      "|     1| 1891|\n",
      "|     0| 7677|\n",
      "+------+-----+\n",
      "\n",
      "+------+-----+\n",
      "|Exited|count|\n",
      "+------+-----+\n",
      "|     0| 1975|\n",
      "|     1| 1891|\n",
      "+------+-----+\n",
      "\n",
      "+------+----------+\n",
      "|Exited|prediction|\n",
      "+------+----------+\n",
      "|     0|       0.0|\n",
      "|     0|       0.0|\n",
      "|     0|       0.0|\n",
      "|     0|       0.0|\n",
      "|     0|       0.0|\n",
      "|     0|       1.0|\n",
      "|     0|       0.0|\n",
      "|     0|       1.0|\n",
      "|     0|       1.0|\n",
      "|     0|       1.0|\n",
      "+------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Accuracy: 0.7531\n",
      "Precision (0): 0.7183, Precision (1): 0.7940\n",
      "Recall (0): 0.8040, Recall (1): 0.7056\n",
      "F1 Score: 0.7528\n",
      "AUC Score: 0.8374\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.functions import col, count, when\n",
    "# from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "# from pyspark.ml.classification import RandomForestClassifier\n",
    "# from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "# # Tạo SparkSession\n",
    "# spark = SparkSession.builder.appName(\"ChurnPrediction\").getOrCreate()\n",
    "\n",
    "# # Đọc dữ liệu\n",
    "# df = spark.read.csv(\"C:/Users/PC/Desktop/Do_an_Big_data/PythonCodes/work/data/Churn_Modelling_FE.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# # Xóa cột không cần thiết\n",
    "# df = df.drop(\"RowNumber\", \"CustomerId\", \"Surname\")\n",
    "\n",
    "# # Chuyển đổi cột nhãn thành số nguyên\n",
    "# df = df.withColumn(\"Exited\", col(\"Exited\").cast(\"integer\"))\n",
    "\n",
    "# # Kiểm tra phân bố dữ liệu trước khi cân bằng\n",
    "# df.groupBy(\"Exited\").count().show()\n",
    "\n",
    "# # **CÂN BẰNG DỮ LIỆU** (UnderSampling lớp 1 & OverSampling lớp 0)\n",
    "# count_class_0 = df.filter(df.Exited == 0).count()\n",
    "# count_class_1 = df.filter(df.Exited == 1).count()\n",
    "\n",
    "# ratio = count_class_0 / count_class_1\n",
    "\n",
    "# if ratio > 1:  # Nếu lớp 0 nhiều hơn, lấy mẫu ngẫu nhiên giảm bớt lớp 0\n",
    "#     df_majority = df.filter(df.Exited == 0).sample(fraction=1/ratio, seed=42)\n",
    "#     df_minority = df.filter(df.Exited == 1)\n",
    "# elif ratio < 1:  # Nếu lớp 1 nhiều hơn, lấy mẫu ngẫu nhiên giảm bớt lớp 1\n",
    "#     df_majority = df.filter(df.Exited == 1).sample(fraction=ratio, seed=42)\n",
    "#     df_minority = df.filter(df.Exited == 0)\n",
    "# else:\n",
    "#     df_majority = df.filter(df.Exited == 0)\n",
    "#     df_minority = df.filter(df.Exited == 1)\n",
    "\n",
    "# df_balanced = df_majority.union(df_minority)\n",
    "\n",
    "# # Kiểm tra lại phân bố dữ liệu sau khi cân bằng\n",
    "# df_balanced.groupBy(\"Exited\").count().show()\n",
    "\n",
    "# # **Chuẩn bị đặc trưng**\n",
    "# feature_cols = [col for col in df_balanced.columns if col != \"Exited\"]\n",
    "# assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "# df_features = assembler.transform(df_balanced)\n",
    "\n",
    "# # **Chuẩn hóa dữ liệu**\n",
    "# scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
    "# scaler_model = scaler.fit(df_features)\n",
    "# df_scaled = scaler_model.transform(df_features)\n",
    "\n",
    "# # **Chia tập train/test**\n",
    "# train_data, test_data = df_scaled.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# # **Huấn luyện mô hình Random Forest**\n",
    "# rf = RandomForestClassifier(featuresCol=\"scaled_features\", labelCol=\"Exited\", numTrees=100, maxDepth=12, minInstancesPerNode=10, featureSubsetStrategy=\"sqrt\")\n",
    "# rf_model = rf.fit(train_data)\n",
    "\n",
    "# # **Lưu mô hình**\n",
    "# rf_model.write().overwrite().save(\"C:/Users/PC/Desktop/Do_an_Big_data/PythonCodes/work/models/rf_model\")\n",
    "\n",
    "# # **Dự đoán trên tập test**\n",
    "# predictions = rf_model.transform(test_data)\n",
    "# predictions.select(\"Exited\", \"prediction\").show(10)\n",
    "\n",
    "# # **Đánh giá mô hình**\n",
    "# accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"Exited\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "# accuracy = accuracy_evaluator.evaluate(predictions)\n",
    "\n",
    "# precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"Exited\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
    "# precision_0 = precision_evaluator.evaluate(predictions, {precision_evaluator.metricLabel: 0})\n",
    "# precision_1 = precision_evaluator.evaluate(predictions, {precision_evaluator.metricLabel: 1})\n",
    "\n",
    "# recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"Exited\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "# recall_0 = recall_evaluator.evaluate(predictions, {recall_evaluator.metricLabel: 0})\n",
    "# recall_1 = recall_evaluator.evaluate(predictions, {recall_evaluator.metricLabel: 1})\n",
    "\n",
    "# f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"Exited\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "# f1_score = f1_evaluator.evaluate(predictions)\n",
    "\n",
    "# auc_evaluator = BinaryClassificationEvaluator(labelCol=\"Exited\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "# auc = auc_evaluator.evaluate(predictions)\n",
    "\n",
    "# # In kết quả\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")\n",
    "# print(f\"Precision (0): {precision_0:.4f}, Precision (1): {precision_1:.4f}\")\n",
    "# print(f\"Recall (0): {recall_0:.4f}, Recall (1): {recall_1:.4f}\")\n",
    "# print(f\"F1 Score: {f1_score:.4f}\")\n",
    "# print(f\"AUC Score: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|Exited|prediction|\n",
      "+------+----------+\n",
      "|     0|       0.0|\n",
      "|     0|       0.0|\n",
      "|     0|       0.0|\n",
      "|     0|       0.0|\n",
      "|     0|       0.0|\n",
      "|     0|       1.0|\n",
      "|     0|       0.0|\n",
      "|     0|       1.0|\n",
      "|     0|       1.0|\n",
      "|     0|       1.0|\n",
      "+------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Accuracy: 0.7517\n",
      "Precision (0): 0.7198, Precision (1): 0.7882\n",
      "Recall (0): 0.7955, Recall (1): 0.7109\n",
      "F1 Score: 0.7515\n",
      "AUC Score: 0.8364\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "# from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# # **CÂN BẰNG DỮ LIỆU** (Using SMOTE or other techniques if necessary)\n",
    "\n",
    "# # **Chuẩn bị đặc trưng**\n",
    "# feature_cols = [col for col in df_balanced.columns if col != \"Exited\"]\n",
    "# assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "# df_features = assembler.transform(df_balanced)\n",
    "\n",
    "# # **Chuẩn hóa dữ liệu**\n",
    "# scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
    "# scaler_model = scaler.fit(df_features)\n",
    "# df_scaled = scaler_model.transform(df_features)\n",
    "\n",
    "# # **Chia tập train/test**\n",
    "# train_data, test_data = df_scaled.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# # **Tuning the Random Forest Classifier**\n",
    "# rf = RandomForestClassifier(featuresCol=\"scaled_features\", labelCol=\"Exited\")\n",
    "\n",
    "# # Define the parameter grid for hyperparameter tuning\n",
    "# paramGrid = (ParamGridBuilder()\n",
    "#              .addGrid(rf.numTrees, [50, 100, 150])\n",
    "#              .addGrid(rf.maxDepth, [5, 10, 15])\n",
    "#              .addGrid(rf.minInstancesPerNode, [1, 2, 5])\n",
    "#              .addGrid(rf.featureSubsetStrategy, [\"auto\", \"sqrt\", \"log2\"])\n",
    "#              .build())\n",
    "\n",
    "# # Cross-validation for better model selection\n",
    "# evaluator = MulticlassClassificationEvaluator(labelCol=\"Exited\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "# cv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# # Fit the model with cross-validation\n",
    "# cv_model = cv.fit(train_data)\n",
    "\n",
    "# # Best Model after Cross-validation\n",
    "# best_rf_model = cv_model.bestModel\n",
    "\n",
    "# # **Dự đoán trên tập test**\n",
    "# predictions = best_rf_model.transform(test_data)\n",
    "# predictions.select(\"Exited\", \"prediction\").show(10)\n",
    "\n",
    "# # **Đánh giá mô hình**\n",
    "# accuracy = evaluator.evaluate(predictions)\n",
    "# precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"Exited\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
    "# precision_0 = precision_evaluator.evaluate(predictions, {precision_evaluator.metricLabel: 0})\n",
    "# precision_1 = precision_evaluator.evaluate(predictions, {precision_evaluator.metricLabel: 1})\n",
    "\n",
    "# recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"Exited\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "# recall_0 = recall_evaluator.evaluate(predictions, {recall_evaluator.metricLabel: 0})\n",
    "# recall_1 = recall_evaluator.evaluate(predictions, {recall_evaluator.metricLabel: 1})\n",
    "\n",
    "# f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"Exited\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "# f1_score = f1_evaluator.evaluate(predictions)\n",
    "\n",
    "# auc_evaluator = BinaryClassificationEvaluator(labelCol=\"Exited\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "# auc = auc_evaluator.evaluate(predictions)\n",
    "\n",
    "# # **In kết quả**\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")\n",
    "# print(f\"Precision (0): {precision_0:.4f}, Precision (1): {precision_1:.4f}\")\n",
    "# print(f\"Recall (0): {recall_0:.4f}, Recall (1): {recall_1:.4f}\")\n",
    "# print(f\"F1 Score: {f1_score:.4f}\")\n",
    "# print(f\"AUC Score: {auc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "henv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
