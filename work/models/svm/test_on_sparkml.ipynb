{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Khởi tạo SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Churn Prediction with SVM\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu từ file CSV\n",
    "customer_data = spark.read.csv('C:/Users/PC/Desktop/Do_an_Big_data/PythonCodes/work/data/Churn_Modelling_FE.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Loại bỏ các cột không cần thiết\n",
    "dataset = customer_data.drop('RowNumber', 'CustomerId', 'Surname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Tách features và label\n",
    "feature_columns = [col for col in dataset.columns if col != 'Exited']\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "data = assembler.transform(dataset)\n",
    "\n",
    "# Chọn cột features và label\n",
    "data = data.select(\"features\", \"Exited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
    "scaler_model = scaler.fit(data)\n",
    "scaled_data = scaler_model.transform(data)\n",
    "\n",
    "# Chọn cột đã chuẩn hóa và label\n",
    "scaled_data = scaled_data.select(\"scaled_features\", \"Exited\").withColumnRenamed(\"scaled_features\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: 7602, Test data shape: 1966\n"
     ]
    }
   ],
   "source": [
    "# Chia dữ liệu thành tập train và test\n",
    "train_data, test_data = scaled_data.randomSplit([0.8, 0.2], seed=0)\n",
    "\n",
    "# In kích thước tập dữ liệu\n",
    "print(f\"Train data shape: {train_data.count()}, Test data shape: {test_data.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Exited|count|\n",
      "+------+-----+\n",
      "|     0| 6134|\n",
      "|     1| 6108|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Đếm số lượng mẫu của từng lớp trong tập train\n",
    "train_counts = train_data.groupBy(\"Exited\").count().collect()\n",
    "majority_class_count = max([row['count'] for row in train_counts])\n",
    "minority_class_count = min([row['count'] for row in train_counts])\n",
    "\n",
    "# Lấy dữ liệu lớp thiểu số và lớp đa số\n",
    "minority_class = train_data.filter(col(\"Exited\") == 1)\n",
    "majority_class = train_data.filter(col(\"Exited\") == 0)\n",
    "\n",
    "# Oversampling lớp thiểu số\n",
    "oversampling_ratio = float(majority_class_count / minority_class_count)  # Chuyển sang float\n",
    "balanced_train_data = majority_class.union(minority_class.sample(withReplacement=True, fraction=oversampling_ratio, seed=0))\n",
    "\n",
    "# Kiểm tra số lượng sau khi cân bằng\n",
    "balanced_train_data.groupBy(\"Exited\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7314\n",
      "Precision: 0.7998\n",
      "Recall: 0.7314\n",
      "F1-score: 0.7515\n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện mô hình SVM\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "svm = LinearSVC(featuresCol=\"features\", labelCol=\"Exited\", maxIter=100, regParam=0.1)\n",
    "svm_model = svm.fit(balanced_train_data)\n",
    "\n",
    "# Dự đoán\n",
    "predictions = svm_model.transform(test_data)\n",
    "\n",
    "# Đánh giá\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Exited\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "f1 = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Lưu mô hình\n",
    "svm_model.save(\"C:/Users/PC/Desktop/Do_an_Big_data/PythonCodes/work/models/svm/spark_svm_model\")\n",
    "\n",
    "# Tắt SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "henv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
